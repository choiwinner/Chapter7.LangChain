{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c72d7e-03c7-42ac-8dad-01951e6ec897",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01dc88f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "#os_key Setting\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일 로드(api key load) \n",
    "#GOOGLE_API_KEY \n",
    "#LANGCHAIN_API_KEY \n",
    "#TAVILY_API_KEY \n",
    "#HUGGINGFACEHUB_API_TOKEN \n",
    "#COHERE_API_KEY \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3d8cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_API_KEY 환경 변수 값 가져오기\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# genai.configure로 GOOGLE API KEY Setting하기기\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a150c91-35fc-4e21-91d6-d1d5cb9858c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN AI로 Chat Model 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9d7617-fa78-4b48-8313-e28a8c4a55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e8dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini로 Chat Model 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa7d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408713d-c56c-40fc-b434-b71475428daf",
   "metadata": {},
   "source": [
    "### StrOutputParser\n",
    "### 대화형 LLM을 구성할 때 주로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e00bfd-6058-4f85-bb2a-8f735dbb81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b02947c3-c4f8-4650-80ea-e6efab85908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 template\n",
    "human_message_prompt = \"'{text}' 여기서 키워드를 뽑아서 콤마로 구분해줘\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_message_prompt)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30cee8f6-9f11-49d0-8fb7-3841d3bbc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_output_parser = chat_prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a9be50-d119-47d4-996a-2d7fb2bf17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain_with_output_parser.invoke({\"text\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e903bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain, framework, language models, applications\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e764660-2d90-4b50-9c02-0a3fa4fb7761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain, framework, developing applications, language models'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31639cf1-0564-450b-ba78-7e2a5293e031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4bd6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StrOutputParser()을 붙이지 않았다면?\n",
    "chain_with_output_parser2 = chat_prompt_template | model #| StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8919b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = chain_with_output_parser2.invoke({\"text\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249cab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain, framework, language models, applications\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e96e24f1-2391-4c20-8700-aeb5be054a6c-0', usage_metadata={'input_tokens': 34, 'output_tokens': 10, 'total_tokens': 44})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 #Output Parser를 붙이지 않으면 LLM Message 그대로 AIMessage가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c4053c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e49f69-ca32-460c-b5b0-7d183519d2df",
   "metadata": {},
   "source": [
    "### CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0595e76-83c6-452d-acf4-81ca2f9b7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a16c3512-cc03-4c67-a1a3-40fd5add5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "949ae263-2854-46e3-8cd5-68ebeb538100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions #CommaSeparatedListOutputParser를 사용했을 때 LLM이 ,로 구문해서 답변을 요청하는 instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d899dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e611eb5d-7141-4d2a-9931-1e341bb51f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"{subject}에 대한 키워드를 추출해줘.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],                           #template의 input_variables로 invoke할 때 지정하는 변수\n",
    "    partial_variables={\"format_instructions\": format_instructions},  \n",
    "    #partial_variables는 이미 만들어 논 변수를 바로 template에 지정하는 변수수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97d8fad0-2590-4c7f-89c3-ba243bdb201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt.invoke({\"subject\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27444590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='LangChain is a framework for developing applications powered by language models.에 대한 키워드를 추출해줘.\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebdea5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_content = \"키워드\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c9c134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"{subject}에 대한 {word}를를 추출해줘.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],            #template의 input_variables로 invoke할 때 지정하는 변수\n",
    "    partial_variables={\"format_instructions\": format_instructions,\"word\": word_content},  \n",
    "    #partial_variables는 이미 만들어 논 변수를 바로 template에 지정하는 변수수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f3cf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = prompt.invoke({\"subject\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be194a40-1af7-488e-897a-9a2a26ee79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='LangChain is a framework for developing applications powered by language models.에 대한 키워드를 추출해줘.\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64d32c32-33cb-4cb5-9abe-53e0d678dd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='LangChain is a framework for developing applications powered by language models.에 대한 키워드를 추출해줘.\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d396c41-46d3-4024-b03c-6c46773c089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1968136a-7024-41cc-ab01-07ea7548a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain.invoke({\"subject\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df854226-332d-4068-b8b7-7c761553262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain', 'framework', 'language models', 'applications']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a24ffa04-1a07-4259-906e-3296a147fbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cec97dac-0914-4b53-addf-f6eff6cd9427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'framework'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4917f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = prompt2 | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74b5519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = chain2.invoke({\"subject\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de8f6f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain', 'framework', 'language models', 'applications']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2401a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StrOutputParser()을 붙이지 않았다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4011608",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain3 = prompt2 | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bba5cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = chain3.invoke({\"subject\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a60642fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain, framework, language models, applications\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-3b515493-dd08-49c4-a83e-d598d6dca3a1-0', usage_metadata={'input_tokens': 55, 'output_tokens': 10, 'total_tokens': 65})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Output Parser를 붙이지 않으면 LLM Message 그대로 AIMessage가 된다.\n",
    "out3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5731c6-6c6d-4998-ba0c-3ea5f6869c95",
   "metadata": {},
   "source": [
    "### 데이터 형식 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01db2e35-6267-4c28-bf5b-b4720c1d44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field #프로토콜을 만들 때 사용하고 Data를 주고 받을 때 형식을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a784804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open AI 사용시\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6091935f-35fe-4b61-9217-a2e405a4b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09ade594-4903-4a29-b4a7-344c09edf52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "\n",
    "class Translation(BaseModel): #class를 만들고 BaseModel을 상속을 받는다.\n",
    "    #translated_text: str는 translated_text라는 이름의 변수와 그 타입을 문자열 (str)로 선언합니다.\n",
    "\n",
    "    #Field(description=\"번역된 텍스트\")는 translated_text 필드에 대한 추가 메타데이터를 제공합니다. \n",
    "    #여기서는 \"번역된 텍스트\"라는 설명을 추가합니다.\n",
    "    translated_text: str = Field(description=\"번역된 텍스트\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "874a516f-b578-44d5-b5b5-eaa28b15eeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"translated_text\": {\"title\": \"Translated Text\", \"description\": \"번역된 텍스트\", \"type\": \"string\"}}, \"required\": [\"translated_text\"]}\\n```'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "query = \"안녕 세상\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Translation)\n",
    "from_instruction = parser.get_format_instructions()\n",
    "from_instruction\n",
    "# translated_text에서 정의한 출력 변수 이름(키)(translated_text), 출력 type:str, 출력하는 변수에 상세 내용:번역된 텍스트\n",
    "# 위의 내용이 prompt의 instruction으로 만들어 진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af68715f-c6d3-4224-b68b-3d72aed89fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"{format_instructions}\\n아래 내용을 번역해라\\n{query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": from_instruction},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95155512-88b2-48df-ba57-44668fcd2237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"translated_text\": {\"title\": \"Translated Text\", \"description\": \"번역된 텍스트\", \"type\": \"string\"}}, \"required\": [\"translated_text\"]}\\n```\\n아래 내용을 번역해라\\n안녕 세상', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"query\": query}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b92b7534-d8e9-40b7-984f-1a3d0308cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "out = chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb95d056-6d2c-4647-a739-1aacd216ff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translated_text': 'Hello world'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecdb8a67-495a-4448-8cc1-d9755293abbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c7c5710-1d42-4f24-9cee-c22818b623f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['translated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5956a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output Parser를 붙이지 않으면 LLM Message 그대로 AIMessage가 된다.\n",
    "\n",
    "chain2 = prompt | model\n",
    "\n",
    "out2 = chain2.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5ef4ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\"translated_text\": \"Hello world\"}\\n```\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1c4cf926-c4e5-490b-b51d-7262af5e8b3b-0', usage_metadata={'input_tokens': 178, 'output_tokens': 15, 'total_tokens': 193})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d22053d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\"translated_text\": \"Hello world\"}\\n```\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a4dc0-bf84-47bc-84b5-70b03ad9518d",
   "metadata": {},
   "source": [
    "### Custom output Parser\n",
    "### output Parser를 자유롭게 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47fe0538-4bab-4bff-aeed-f124a304c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    #LLM의 message가 text로 들어 온다.\n",
    "    def parse(self, text):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        #print(text)\n",
    "        return text.strip().split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "71d5ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 template\n",
    "human_message_prompt = \"'{text}' 여기서 키워드를 뽑아서 콤마로 구분해줘\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_message_prompt)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a46f9c5-1516-4894-b4bd-2fb4531d9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_comma_parser = chat_prompt_template | model | CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2acd2dd4-b3a4-44f7-945f-6246498ac43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain_with_comma_parser.invoke({\"text\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38147433-4d9f-40f1-9a3c-e77dc6b51e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain', 'framework', 'language models', 'applications']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4116ad7-6aae-450e-8fad-8308f4c13ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain\n",
      "framework\n",
      "language models\n",
      "applications\n"
     ]
    }
   ],
   "source": [
    "for keyword in out:\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a74ca-2447-4a3b-831e-09c6228ea2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
